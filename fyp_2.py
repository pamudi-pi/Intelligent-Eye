# -*- coding: utf-8 -*-
"""FYP_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ko7kVbyuSmHWQ7oCVwzEInkNlgXc1e5K
"""

# Install necessary libraries
!pip install ultralytics
!pip install opencv-python-headless
!pip install moviepy

import cv2
import numpy as np
from moviepy.editor import VideoFileClip
from google.colab import files
from ultralytics import YOLO

# Load YOLOv8 instance segmentation model
model = YOLO('yolov8n-seg.pt')

# Function to apply YOLOv8 instance segmentation to a single frame
def segment_frame_yolo(frame):
    results = model(frame)
    annotated_frame = results[0].plot()  # Draw segmentation masks on the frame
    return cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR)  # Ensure proper format for OpenCV

# Upload video file
print("Upload your video file")
uploaded = files.upload()
video_path = list(uploaded.keys())[0]

# Process video
output_path = "segmented_video.mp4"

clip = VideoFileClip(video_path)
fps = clip.fps

# OpenCV Video Writer
height, width = clip.size
out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (width, height))

for frame in clip.iter_frames():
    frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
    segmented_frame = segment_frame_yolo(frame_bgr)
    out.write(segmented_frame)  # Write the processed frame to the video

out.release()

# Allow download of the processed video
print("Download your processed video")
files.download(output_path)

# Install necessary libraries
!pip install ultralytics opencv-python-headless moviepy

# Import required libraries
from ultralytics import YOLO
import cv2
from google.colab import files
import os

# Upload the video
print("Please upload your video file")
uploaded = files.upload()

# Get the uploaded video filename
video_file = list(uploaded.keys())[0]

# Load the YOLOv8 model for instance segmentation
model = YOLO('yolov8x-seg.pt')  # Use 'yolov8x-seg.pt' or other trained models

# Create a directory for output
output_dir = "processed_videos"
os.makedirs(output_dir, exist_ok=True)
output_video_path = os.path.join(output_dir, f"processed_{video_file}")

# Process the video
cap = cv2.VideoCapture(video_file)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

print("Processing the video...")
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Perform instance segmentation on each frame
    results = model(frame)

    # Get the processed frame with predictions
    annotated_frame = results[0].plot()  # Visualize predictions on the frame

    # Write the frame to the output video
    out.write(annotated_frame)

cap.release()
out.release()
print(f"Processing completed. Video saved as {output_video_path}")

# Allow downloading the processed video
from google.colab import files
files.download(output_video_path)